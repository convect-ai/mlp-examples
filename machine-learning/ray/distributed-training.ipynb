{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690629c2-5e72-4835-a39f-d72ecc8f3612",
   "metadata": {},
   "source": [
    "# Distributed training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c422300-3917-4081-a640-f15fd78fd3c2",
   "metadata": {},
   "source": [
    "First, set up your dataset and model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c7a284-3060-41c9-85f6-1a4d74e6724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "num_samples = 20\n",
    "input_size = 10\n",
    "layer_size = 15\n",
    "output_size = 5\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, layer_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(layer_size, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layer2(self.relu(self.layer1(input)))\n",
    "\n",
    "# In this example we use a randomly generated dataset.\n",
    "input = torch.randn(num_samples, input_size)\n",
    "labels = torch.randn(num_samples, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1a7b9-33d2-4bea-ae3b-ce4982f117bd",
   "metadata": {},
   "source": [
    "Now define your single-worker PyTorch training function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f844d48b-91bf-419a-9521-bddd60baeb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_func():\n",
    "    num_epochs = 3\n",
    "    model = NeuralNetwork()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        output = model(input)\n",
    "        loss = loss_fn(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"epoch: {epoch}, loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f6bf55-0f8a-4e6e-8879-3ac59197b292",
   "metadata": {},
   "source": [
    "This training function can be executed with:\n",
    "\n",
    "```python\n",
    "train_func()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c95384-29a2-4be5-9d54-cc4512a99fca",
   "metadata": {},
   "source": [
    "Now letâ€™s convert this to a distributed multi-worker training function!\n",
    "\n",
    "All you have to do is use the `ray.train.torch.prepare_model` and `ray.train.torch.prepare_data_loader` utility functions to easily setup your model & data for distributed training. This will automatically wrap your model with `DistributedDataParallel` and place it on the right device, and add `DistributedSampler` to your DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "813be115-5ca7-4e8a-9446-c5f7b7c16f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ray import train\n",
    "import ray.train.torch\n",
    "\n",
    "def train_func_distributed():\n",
    "    num_epochs = 5\n",
    "    model = NeuralNetwork()\n",
    "    model = train.torch.prepare_model(model)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        output = model(input)\n",
    "        loss = loss_fn(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"epoch: {epoch}, loss: {loss.item()}\")\n",
    "        train.report(loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d04e11f-e4ba-4cf7-879b-9af3881ccec3",
   "metadata": {},
   "source": [
    "Let's set up a remote cluster we use for the distributed training\n",
    "\n",
    "```bash\n",
    "~/kubectl apply -f ray-cluster.yaml\n",
    "```\n",
    "\n",
    "This is going to start a cluster with 2 workers and support auto-scaling.\n",
    "\n",
    "To verify the cluster is acutally running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179c0e8e-a26c-4243-a2a2-d14d373601bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME              STATUS    RESTARTS   AGE\n",
      "example-cluster   Running   0          30m\n"
     ]
    }
   ],
   "source": [
    "!~/kubectl get rayclusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4bb408-3212-4ac0-bfee-936be1b434c8",
   "metadata": {},
   "source": [
    "Then let's connect to the cluster and also set up the worker runtime environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1731589b-d07f-40c3-ba35-225f1eaef103",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"ray://example-cluster-ray-head:10001\"\n",
    "\n",
    "env = {\n",
    "    \"pip\": \"requirements-env.txt\"\n",
    "}\n",
    "\n",
    "context = ray.init(url, runtime_env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e67c6-083b-4433-900d-32e422b37693",
   "metadata": {},
   "source": [
    "Then, instantiate a `Trainer` that uses a \"torch\" backend with 2 workers, and use it to run the new training function!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c7ba0f3-526a-47b3-a0b7-8dc6223a0892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 18:09:58,847\tINFO trainer.py:243 -- Trainer logs will be logged in: /home/jovyan/ray_results/train_2022-07-06_18-09-58\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=802, ip=10.10.125.125)\u001b[0m 2022-07-06 16:10:05,717\tINFO torch.py:347 -- Setting up process group for: env:// [rank=1, world_size=3]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=803, ip=10.10.125.125)\u001b[0m 2022-07-06 16:10:05,719\tINFO torch.py:347 -- Setting up process group for: env:// [rank=2, world_size=3]\n",
      "2022-07-06 18:10:05,751\tINFO trainer.py:249 -- Run results will be logged in: /home/jovyan/ray_results/train_2022-07-06_18-09-58/run_001\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=351, ip=10.10.86.36)\u001b[0m 2022-07-06 16:10:05,698\tINFO torch.py:347 -- Setting up process group for: env:// [rank=0, world_size=3]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=351, ip=10.10.86.36)\u001b[0m 2022-07-06 16:10:05,784\tINFO torch.py:98 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=351, ip=10.10.86.36)\u001b[0m 2022-07-06 16:10:05,785\tINFO torch.py:132 -- Wrapping provided model in DDP.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=802, ip=10.10.125.125)\u001b[0m 2022-07-06 16:10:05,785\tINFO torch.py:98 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=802, ip=10.10.125.125)\u001b[0m 2022-07-06 16:10:05,785\tINFO torch.py:132 -- Wrapping provided model in DDP.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=803, ip=10.10.125.125)\u001b[0m 2022-07-06 16:10:05,785\tINFO torch.py:98 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=803, ip=10.10.125.125)\u001b[0m 2022-07-06 16:10:05,785\tINFO torch.py:132 -- Wrapping provided model in DDP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"loss\": 1.4390658140182495,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.015300273895263672,\n",
      "        \"_training_iteration\": 1\n",
      "    },\n",
      "    {\n",
      "        \"loss\": 1.4390658140182495,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.012506723403930664,\n",
      "        \"_training_iteration\": 1\n",
      "    },\n",
      "    {\n",
      "        \"loss\": 1.4390658140182495,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.009943485260009766,\n",
      "        \"_training_iteration\": 1\n",
      "    }\n",
      "]\n",
      "[\n",
      "    {\n",
      "        \"loss\": 1.3922909498214722,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.003665447235107422,\n",
      "        \"_training_iteration\": 2\n",
      "    },\n",
      "    {\n",
      "        \"loss\": 1.3922909498214722,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.0036590099334716797,\n",
      "        \"_training_iteration\": 2\n",
      "    },\n",
      "    {\n",
      "        \"loss\": 1.3922909498214722,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.0033502578735351562,\n",
      "        \"_training_iteration\": 2\n",
      "    }\n",
      "]\n",
      "[\n",
      "    {\n",
      "        \"loss\": 1.35182785987854,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.00802922248840332,\n",
      "        \"_training_iteration\": 3\n",
      "    },\n",
      "    {\n",
      "        \"loss\": 1.35182785987854,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.008035659790039062,\n",
      "        \"_training_iteration\": 3\n",
      "    },\n",
      "    {\n",
      "        \"loss\": 1.35182785987854,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.008085012435913086,\n",
      "        \"_training_iteration\": 3\n",
      "    }\n",
      "]\n",
      "[\n",
      "    {\n",
      "        \"loss\": 1.3168185949325562,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.008973836898803711,\n",
      "        \"_training_iteration\": 4\n",
      "    },\n",
      "    {\n",
      "        \"loss\": 1.3168185949325562,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.008949995040893555,\n",
      "        \"_training_iteration\": 4\n",
      "    },\n",
      "    {\n",
      "        \"loss\": 1.3168185949325562,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.008939743041992188,\n",
      "        \"_training_iteration\": 4\n",
      "    }\n",
      "]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=802, ip=10.10.125.125)\u001b[0m epoch: 0, loss: 1.4390658140182495\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=802, ip=10.10.125.125)\u001b[0m epoch: 1, loss: 1.3922909498214722\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=802, ip=10.10.125.125)\u001b[0m epoch: 2, loss: 1.35182785987854\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=802, ip=10.10.125.125)\u001b[0m epoch: 3, loss: 1.3168185949325562\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=802, ip=10.10.125.125)\u001b[0m epoch: 4, loss: 1.286351203918457\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=803, ip=10.10.125.125)\u001b[0m epoch: 0, loss: 1.4390658140182495\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=803, ip=10.10.125.125)\u001b[0m epoch: 1, loss: 1.3922909498214722\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=803, ip=10.10.125.125)\u001b[0m epoch: 2, loss: 1.35182785987854\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=803, ip=10.10.125.125)\u001b[0m epoch: 3, loss: 1.3168185949325562\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=803, ip=10.10.125.125)\u001b[0m epoch: 4, loss: 1.286351203918457\n",
      "[\n",
      "    {\n",
      "        \"loss\": 1.286351203918457,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.007012367248535156,\n",
      "        \"_training_iteration\": 5\n",
      "    },\n",
      "    {\n",
      "        \"loss\": 1.286351203918457,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.007022380828857422,\n",
      "        \"_training_iteration\": 5\n",
      "    },\n",
      "    {\n",
      "        \"loss\": 1.286351203918457,\n",
      "        \"_timestamp\": 1657149005,\n",
      "        \"_time_this_iter_s\": 0.006979942321777344,\n",
      "        \"_training_iteration\": 5\n",
      "    }\n",
      "]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=351, ip=10.10.86.36)\u001b[0m epoch: 0, loss: 1.4390658140182495\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=351, ip=10.10.86.36)\u001b[0m epoch: 1, loss: 1.3922909498214722\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=351, ip=10.10.86.36)\u001b[0m epoch: 2, loss: 1.35182785987854\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=351, ip=10.10.86.36)\u001b[0m epoch: 3, loss: 1.3168185949325562\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=351, ip=10.10.86.36)\u001b[0m epoch: 4, loss: 1.286351203918457\n"
     ]
    }
   ],
   "source": [
    "from ray.train.callbacks import PrintCallback, TBXLoggerCallback\n",
    "from ray.train import Trainer\n",
    "\n",
    "trainer = Trainer(backend=\"torch\", num_workers=3)\n",
    "\n",
    "# For GPU Training, set `use_gpu` to True.\n",
    "# trainer = Trainer(backend=\"torch\", num_workers=4, use_gpu=True)\n",
    "\n",
    "trainer.start()\n",
    "results = trainer.run(\n",
    "    train_func_distributed,\n",
    "    callbacks=[PrintCallback(), TBXLoggerCallback()]\n",
    ")\n",
    "trainer.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c286c719-b207-4408-ad04-eeffec7d2622",
   "metadata": {},
   "source": [
    "We can start a tensorboard to monitor the training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3249bcb-38f5-412a-8070-333901264c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b110a377-e4c3-49e9-a456-ed0444677c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5b5585a07460dfdf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5b5585a07460dfdf\");\n",
       "          const url = new URL(\"/user/yuhui@convect.ai/proxy/6009/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir  {str(trainer.latest_run_dir)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c975ea55-2129-4b35-88a6-49e6b915ff65",
   "metadata": {},
   "source": [
    "# Parallel hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2c136-dfdc-4daa-9652-12ecf460f6d3",
   "metadata": {},
   "source": [
    "Let's first modify our training function by taking into a config object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "871366f7-1b5f-4a95-8a68-7513005b909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_func_distributed_tunable(config):\n",
    "    num_epochs = 10\n",
    "    lr = config[\"lr\"]\n",
    "    model = NeuralNetwork()\n",
    "    model = train.torch.prepare_model(model)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        output = model(input)\n",
    "        loss = loss_fn(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"epoch: {epoch}, loss: {loss.item()}\")\n",
    "        train.report(loss=loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf58b0b-19d6-4c88-a52e-9629546fa9bd",
   "metadata": {},
   "source": [
    "Then start the tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6a34e1-c9b8-4504-872a-d4f2a4a5d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable = trainer.to_tune_trainable(train_func_distributed_tunable)\n",
    "\n",
    "from ray import tune\n",
    "import numpy as np\n",
    "\n",
    "analysis = tune.run(\n",
    "    trainable,\n",
    "    mode=\"min\",\n",
    "    metric=\"loss\",\n",
    "    num_samples=3,\n",
    "    config={\n",
    "        \"lr\": tune.uniform(0.01, 0.05)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(analysis.get_best_config(metric=\"loss\", mode=\"min\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d7e90c-830b-4882-a135-8a78a48c6355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ray]",
   "language": "python",
   "name": "conda-env-.conda-ray-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
